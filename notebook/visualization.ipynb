{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import polyscope as ps\n",
    "import mcubes\n",
    "import trimesh\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from types import SimpleNamespace\n",
    "\n",
    "try:\n",
    "    os.chdir(pathlib.Path(initial).parent)\n",
    "except NameError:\n",
    "    initial = os.getcwd()\n",
    "    os.chdir(pathlib.Path(initial).parent)\n",
    "    \n",
    "from iarap.model.neural_rtf import NeuralRTF, NeuralRTFConfig\n",
    "from iarap.model.neural_sdf import NeuralSDF, NeuralSDFConfig\n",
    "from iarap.utils.meshing import *\n",
    "\n",
    "np.random.seed(1234567)\n",
    "torch.manual_seed(1234567)\n",
    "ps.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_point_invert(g, y, iters=15, verbose=False):\n",
    "    with torch.no_grad():\n",
    "        x = y\n",
    "        dim = x.size(-1)\n",
    "        for i in range(iters):\n",
    "            x = y - g(x)\n",
    "            if verbose:\n",
    "                err = (y - (x + g(x))).view(-1, dim).norm(dim=-1).mean()\n",
    "                err = err.detach().cpu().item()\n",
    "                print(\"iter:%d err:%s\" % (i, err))\n",
    "    return x\n",
    "\n",
    "class LipBoundedPosEnc(nn.Module):\n",
    "\n",
    "    def __init__(self, inp_features, n_freq, cat_inp=True):\n",
    "        super().__init__()\n",
    "        self.inp_feat = inp_features\n",
    "        self.n_freq = n_freq\n",
    "        self.cat_inp = cat_inp\n",
    "        self.out_dim = 2 * self.n_freq * self.inp_feat\n",
    "        if self.cat_inp:\n",
    "            self.out_dim += self.inp_feat\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: (bs, npoints, inp_features)\n",
    "        :return: (bs, npoints, 2 * out_features + inp_features)\n",
    "        \"\"\"\n",
    "        assert len(x.size()) == 3\n",
    "        bs, npts = x.size(0), x.size(1)\n",
    "        const = (2 ** torch.arange(self.n_freq) * np.pi).view(1, 1, 1, -1)\n",
    "        const = const.to(x)\n",
    "\n",
    "        # Out shape : (bs, npoints, out_feat)\n",
    "        cos_feat = torch.cos(const * x.unsqueeze(-1)).view(\n",
    "            bs, npts, self.inp_feat, -1)\n",
    "        sin_feat = torch.sin(const * x.unsqueeze(-1)).view(\n",
    "            bs, npts, self.inp_feat, -1)\n",
    "        out = torch.cat(\n",
    "            [sin_feat, cos_feat], dim=-1).view(\n",
    "            bs, npts, 2 * self.inp_feat * self.n_freq)\n",
    "        const_norm = torch.cat(\n",
    "            [const, const], dim=-1).view(\n",
    "            1, 1, 1, self.n_freq * 2).expand(\n",
    "            -1, -1, self.inp_feat, -1).reshape(\n",
    "            1, 1, 2 * self.inp_feat * self.n_freq)\n",
    "\n",
    "        if self.cat_inp:\n",
    "            out = torch.cat([out, x], dim=-1)\n",
    "            const_norm = torch.cat(\n",
    "                [const_norm, torch.ones(1, 1, self.inp_feat).to(x)], dim=-1)\n",
    "\n",
    "            return out / const_norm / np.sqrt(self.n_freq * 2 + 1)\n",
    "        else:\n",
    "\n",
    "            return out / const_norm / np.sqrt(self.n_freq * 2)\n",
    "\n",
    "\n",
    "class InvertibleResBlockLinear(nn.Module):\n",
    "\n",
    "    def __init__(self, inp_dim, hid_dim, nblocks=1,\n",
    "                 nonlin='leaky_relu',\n",
    "                 pos_enc_freq=None):\n",
    "        super().__init__()\n",
    "        self.dim = inp_dim\n",
    "        self.nblocks = nblocks\n",
    "\n",
    "        self.pos_enc_freq = pos_enc_freq\n",
    "        if self.pos_enc_freq is not None:\n",
    "            inp_dim_af_pe = self.dim * (self.pos_enc_freq * 2 + 1)\n",
    "            self.pos_enc = LipBoundedPosEnc(self.dim, self.pos_enc_freq)\n",
    "        else:\n",
    "            self.pos_enc = lambda x: x\n",
    "            inp_dim_af_pe = inp_dim\n",
    "\n",
    "        self.blocks = nn.ModuleList()\n",
    "        self.blocks.append(nn.utils.spectral_norm(\n",
    "            nn.Linear(inp_dim_af_pe, hid_dim)))\n",
    "        for _ in range(self.nblocks):\n",
    "            self.blocks.append(\n",
    "                nn.utils.spectral_norm(\n",
    "                    nn.Linear(hid_dim, hid_dim),\n",
    "                )\n",
    "            )\n",
    "        self.blocks.append(\n",
    "            nn.utils.spectral_norm(\n",
    "                nn.Linear(hid_dim, self.dim),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.nonlin = nonlin.lower()\n",
    "        if self.nonlin == 'leaky_relu':\n",
    "            self.act = nn.LeakyReLU()\n",
    "        elif self.nonlin == 'relu':\n",
    "            self.act = nn.ReLU()\n",
    "        elif self.nonlin == 'elu':\n",
    "            self.act = nn.ELU()\n",
    "        elif self.nonlin == 'softplus':\n",
    "            self.act = nn.Softplus()\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def forward_g(self, x):\n",
    "        orig_dim = len(x.size())\n",
    "        if orig_dim == 2:\n",
    "            x = x.unsqueeze(0)\n",
    "\n",
    "        y = self.pos_enc(x)\n",
    "        for block in self.blocks[:-1]:\n",
    "            y = self.act(block(y))\n",
    "        y = self.blocks[-1](y)\n",
    "\n",
    "        if orig_dim == 2:\n",
    "            y = y.squeeze(0)\n",
    "\n",
    "        return y\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.forward_g(x)\n",
    "\n",
    "    def invert(self, y, verbose=False, iters=15):\n",
    "        return fixed_point_invert(\n",
    "            lambda x: self.forward_g(x), y, iters=iters, verbose=verbose\n",
    "        )\n",
    "\n",
    "\n",
    "class InvertibleMLP(nn.Module):\n",
    "\n",
    "    def __init__(self, _, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.dim = cfg.dim\n",
    "        self.out_dim = cfg.out_dim\n",
    "        self.hidden_size = cfg.hidden_size\n",
    "        self.n_blocks = cfg.n_blocks\n",
    "        self.n_g_blocks = getattr(cfg, \"n_g_blocks\", 1)\n",
    "\n",
    "        # Network modules\n",
    "        self.blocks = nn.ModuleList()\n",
    "        for _ in range(self.n_blocks):\n",
    "            self.blocks.append(\n",
    "                InvertibleResBlockLinear(\n",
    "                    self.dim, self.hidden_size,\n",
    "                    nblocks=self.n_g_blocks, nonlin=cfg.nonlin,\n",
    "                    pos_enc_freq=getattr(cfg, \"pos_enc_freq\", None),\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: (bs, npoints, self.dim) Input coordinate (xyz)\n",
    "        :return: (bs, npoints, self.dim) Gradient (self.dim dimension)\n",
    "        \"\"\"\n",
    "        out = x\n",
    "        for block in self.blocks:\n",
    "            out = block(out)\n",
    "        return out\n",
    "    \n",
    "    def deform(self, x):\n",
    "        return self(x)\n",
    "\n",
    "    def inverse(self, y, verbose=False, iters=15):\n",
    "        x = y\n",
    "        for block in self.blocks[::-1]:\n",
    "            x = block.invert(x, verbose=verbose, iters=iters)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "SDF_CKPT = 'assets/weights/sdf/dragon.pt'\n",
    "RTF_CKPT = 'C:\\\\Users\\\\pc\\\\Documents\\\\GLADIA\\\\nfgp-private-fork\\\\logs\\\\armadillo-arm_front-nfgp\\\\checkpoints\\\\epoch_499_iters_50000.pt'\n",
    "DEFORM_CLASS = InvertibleMLP\n",
    "NUM_PATCH_PTS = 30\n",
    "PATCH_RADIUS = 0.2\n",
    "SURFACE_SAMPLES = 12611\n",
    "SPACE_SAMPLES = 0\n",
    "CHUNK = 300000\n",
    "MC_RESOLUTION = 512\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_model: NeuralSDF = NeuralSDFConfig().setup().to(DEVICE)\n",
    "if len(SDF_CKPT) > 0:\n",
    "    sdf_model.load_state_dict(torch.load(SDF_CKPT))\n",
    "\n",
    "if DEFORM_CLASS is NeuralRTF:\n",
    "    rtf_model: NeuralRTF = NeuralRTFConfig().setup().to(DEVICE)\n",
    "    if len(RTF_CKPT) > 0:\n",
    "        rtf_model.load_state_dict(torch.load(RTF_CKPT))\n",
    "elif DEFORM_CLASS is InvertibleMLP:\n",
    "    rtf_model: InvertibleMLP = InvertibleMLP(None, SimpleNamespace(**{\n",
    "        'dim': 3, 'hidden_size': 256, 'n_blocks': 6,\n",
    "        'nonlin': 'elu', 'out_dim': 3, 'pos_enc_freq': 5\n",
    "    })).to(DEVICE)\n",
    "    if len(RTF_CKPT) > 0:\n",
    "        state_dict = {k: v for k, v in torch.load(RTF_CKPT)['next_dec'].items() if k.split('.')[0] == 'deform'}\n",
    "        state_dict = {'.'.join(k.split('.')[1:]): v for k, v in state_dict.items()}\n",
    "        rtf_model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0363a03b984b4810bc1e70b77f243e83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/448 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "steps = torch.linspace(-1.0, 1.0, MC_RESOLUTION, device=DEVICE)\n",
    "xx, yy, zz = torch.meshgrid(steps, steps, steps, indexing=\"ij\")\n",
    "volume = torch.vstack([xx.ravel(), yy.ravel(), zz.ravel()]).T.float()\n",
    "f_eval = []\n",
    "with torch.no_grad():\n",
    "    for sample in tqdm(torch.split(volume, CHUNK, dim=0)):\n",
    "        f_eval.append(sdf_model(sample.contiguous())['dist'].cpu().numpy())\n",
    "f_volume = np.concatenate(f_eval, axis=0).reshape(*([MC_RESOLUTION] * 3))\n",
    "shape_verts, shape_faces = mcubes.marching_cubes(f_volume, 0.0)\n",
    "shape_verts /= MC_RESOLUTION // 2\n",
    "shape_verts -= 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minor examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surface projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial = torch.tensor([[-0.7, 0.0, 0.0], \n",
    "                        [-0.6, 0.1, 0.0],\n",
    "                        [-0.5, 0.0, 0.3]], device=DEVICE)\n",
    "\n",
    "trajectory = [initial]\n",
    "offsets = []\n",
    "\n",
    "point = initial\n",
    "for it in range(5):\n",
    "    point_new = sdf_model.project_nearest(point)\n",
    "    trajectory.append(point_new)\n",
    "    offsets.append(point_new - point)\n",
    "    point = point_new\n",
    "\n",
    "offsets.append(torch.zeros_like(initial))\n",
    "trajectory = torch.cat(trajectory, dim=0).view(-1, 3).cpu().detach().numpy()\n",
    "offsets = torch.cat(offsets, dim=0).view(-1, 3).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.register_surface_mesh(\"Input Shape\", shape_verts, shape_faces, enabled=True)\n",
    "traj_pc = ps.register_point_cloud(\"Trajectory\", trajectory, enabled=True)\n",
    "traj_pc.add_vector_quantity(\"Offsets\", offsets, vectortype='ambient', enabled=True)\n",
    "ps.show()\n",
    "ps.remove_all_structures()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Patch Meshing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patch Sampling and Triangulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches = {'vert': {}, 'triv': {}}\n",
    "sampling_methods = {'runif': sphere_random_uniform,\n",
    "                    'rnorm': sphere_gaussian_radius,\n",
    "                    'linear': sphere_sunflower,\n",
    "                    'normal': gaussian_max_norm}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, sampler in sampling_methods.items():\n",
    "    patch = get_patch_mesh(sampler, delaunay, NUM_PATCH_PTS, PATCH_RADIUS, DEVICE)\n",
    "    patches['vert'][name] = patch[0].cpu().numpy()\n",
    "    patches['triv'][name] = patch[1].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for name in sampling_methods.keys():\n",
    "    offset = np.zeros_like(patches['vert'][name])\n",
    "    offset[:, 0] = PATCH_RADIUS * (2.2 * i)\n",
    "    vert = patches['vert'][name] + offset\n",
    "    ps.register_surface_mesh(f\"{name}_patch\", vert, patches['triv'][name], enabled=True, edge_width=1)\n",
    "    i += 1\n",
    "\n",
    "ps.show()\n",
    "ps.remove_all_structures()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patch Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECTED_PATCH = 'linear'\n",
    "\n",
    "plane_coords, triangles = patches['vert'][SELECTED_PATCH], patches['triv'][SELECTED_PATCH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# surf_sample = torch.tensor([[-0.54,  0.365,  0.08]], device=DEVICE)\n",
    "# for it in range(5):\n",
    "#     surf_sample = sdf_model.project_nearest(surf_sample).detach()\n",
    "\n",
    "surf_sample = sdf_model.sample_zero_level_set(SURFACE_SAMPLES, 0.05, 10000, (-1, 1), 15).detach()\n",
    "space_sample = torch.rand(SPACE_SAMPLES, 3, device=DEVICE) * 2 - 1\n",
    "samples = torch.cat([surf_sample, space_sample], dim=0).detach()\n",
    "\n",
    "sdf_outs = sdf_model(samples, with_grad=True)\n",
    "sample_dist, patch_normals = sdf_outs['dist'], F.normalize(sdf_outs['grad'], dim=-1)\n",
    "tangent_planes = sdf_model.tangent_plane(samples).cpu().numpy()\n",
    "\n",
    "tangent_coords = (np.expand_dims(tangent_planes, 1) @ plane_coords.reshape(1, -1, 3, 1)).squeeze() \n",
    "tangent_pts = tangent_coords + samples.unsqueeze(1).detach().cpu().numpy()\n",
    "triangles_all = np.expand_dims(triangles, 0) + (tangent_pts.shape[1] * np.arange(0, tangent_pts.shape[0]).reshape(-1, 1, 1))\n",
    "\n",
    "tangent_pts = tangent_pts.reshape(-1, 3)\n",
    "triangles_all = triangles_all.reshape(-1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.register_surface_mesh(\"Input Shape\", shape_verts, shape_faces, enabled=True, transparency=0.5)\n",
    "ps.register_surface_mesh(\"Projected Patches\", tangent_pts, triangles_all, enabled=True, edge_width=1.0)\n",
    "normals_pc = ps.register_point_cloud(\"Normal Origins\", samples.cpu().detach().numpy(), radius=0.0, enabled=True)\n",
    "normals_pc.add_vector_quantity(\"Patch Normals\", patch_normals.cpu().detach().numpy(), enabled=True)\n",
    "ps.show()\n",
    "ps.remove_all_structures()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patch Fitting/Deformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_set_verts = torch.from_numpy(tangent_pts).to(DEVICE, torch.float).reshape(\n",
    "    SURFACE_SAMPLES + SPACE_SAMPLES, NUM_PATCH_PTS, 3)\n",
    "for it in range(15):\n",
    "    level_set_verts = sdf_model.project_level_sets(level_set_verts, sample_dist).detach()\n",
    "level_set_verts = level_set_verts.cpu().detach().view(-1, 3).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.register_surface_mesh(\"Input Shape\", shape_verts, shape_faces, enabled=True, transparency=0.5)\n",
    "ps.register_surface_mesh(\"Deformed Patches\", level_set_verts, triangles_all, enabled=True, edge_width=1.0)\n",
    "normals_pc = ps.register_point_cloud(\"Normal Origins\", samples.cpu().detach().numpy(), radius=0.0, enabled=True)\n",
    "normals_pc.add_vector_quantity(\"Patch Normals\", patch_normals.cpu().detach().numpy(), enabled=True)\n",
    "ps.show()\n",
    "ps.remove_all_structures()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LPM Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.register_surface_mesh(\"marching cubes mesh\", shape_verts, shape_faces, enabled=True, transparency=0.5)\n",
    "ps.show()\n",
    "ps.remove_all_structures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(378330, 3) (756660, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.0050, device='cuda:0'), tensor(0.0017, device='cuda:0'))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_mesh_obj = trimesh.Trimesh(shape_verts, shape_faces)\n",
    "print(shape_verts.shape, shape_faces.shape)\n",
    "NUM_TESTS = 300000\n",
    "with torch.no_grad():\n",
    "    tests = torch.from_numpy(mc_mesh_obj.sample(NUM_TESTS)).to(DEVICE, torch.float)\n",
    "    dists = sdf_model.distance(tests)\n",
    "    error_max = (dists.abs()).max()\n",
    "    error_mean = (dists.abs()).mean()\n",
    "error_max, error_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0037595845510896343 0.08020722948562231\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((378330, 3), (630550, 3))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_mean_edge = mc_mesh_obj.edges_unique_length.mean()\n",
    "\n",
    "patch_mesh_obj = trimesh.Trimesh(plane_coords, triangles)\n",
    "patch_mean_edge = patch_mesh_obj.edges_unique_length.mean()\n",
    "patch_mesh_obj.vertices *= (mc_mean_edge / patch_mean_edge)\n",
    "norm_plane_coords = patch_mesh_obj.vertices\n",
    "print(mc_mean_edge, patch_mean_edge)\n",
    "\n",
    "tangent_coords = (np.expand_dims(tangent_planes, 1) @ norm_plane_coords.reshape(1, -1, 3, 1)).squeeze() \n",
    "tangent_pts = (tangent_coords + samples.unsqueeze(1).detach().cpu().numpy()).reshape(-1, 3)\n",
    "level_set_verts = torch.from_numpy(tangent_pts).to(DEVICE, torch.float).reshape(\n",
    "    SURFACE_SAMPLES + SPACE_SAMPLES, NUM_PATCH_PTS, 3)\n",
    "for it in range(15):\n",
    "    level_set_verts = sdf_model.project_level_sets(level_set_verts, sample_dist).detach()\n",
    "level_set_verts = level_set_verts.cpu().detach().view(-1, 3).numpy()\n",
    "level_set_verts.shape, triangles_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.register_surface_mesh(\"local patch mesh\", level_set_verts, triangles_all, enabled=True, transparency=0.5)\n",
    "ps.show()\n",
    "ps.remove_all_structures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0008, device='cuda:0'), tensor(1.7795e-05, device='cuda:0'))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch_mesh_obj = trimesh.Trimesh(level_set_verts, triangles_all)\n",
    "NUM_TESTS = 300000\n",
    "with torch.no_grad():\n",
    "    tests = torch.from_numpy(patch_mesh_obj.sample(NUM_TESTS)).to(DEVICE, torch.float)\n",
    "    dists = sdf_model.distance(tests)\n",
    "    error_max = (dists.abs()).max()\n",
    "    error_mean = (dists.abs()).mean()\n",
    "error_max, error_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dragon_camera = {\"farClipRatio\":20.0,\"fov\":45.0,\"nearClipRatio\":0.005,\"projectionMode\":\"Perspective\",\"viewMat\":[0.825720965862274,6.63567334413528e-09,0.564077973365784,0.168529987335205,0.20917721092701,0.928702771663666,-0.30620214343071,-0.0139824077486992,-0.523861527442932,0.370830506086349,0.766852080821991,-1.84108781814575,0.0,0.0,0.0,1.0],\"windowHeight\":1200,\"windowWidth\":1600}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense Mesh Deformation\n",
    "\n",
    "We deform the original input mesh to evaluate all properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_INPUT_MESH = 'assets/mesh/armadillo.ply'\n",
    "LOAD_DEFORMED_MESH = 'assets\\\\mesh\\\\arap_results\\\\spokes_and_rims\\\\dino_arap_snout_experiment.off'\n",
    "\n",
    "mesh_input = trimesh.load(LOAD_INPUT_MESH, force='mesh')\n",
    "\n",
    "mesh_input.vertices -= np.expand_dims(mesh_input.centroid, axis=0)\n",
    "mesh_input.vertices /= np.abs(mesh_input.vertices).max()\n",
    "mesh_input.vertices *= 0.8\n",
    "\n",
    "if len(LOAD_DEFORMED_MESH) > 0:\n",
    "    mesh_deform = trimesh.load(LOAD_DEFORMED_MESH, force='mesh')\n",
    "else:\n",
    "    in_verts = torch.from_numpy(mesh_input.vertices).float()\n",
    "    def_verts = []\n",
    "    with torch.no_grad():\n",
    "        for sample in torch.split(in_verts, CHUNK, dim=0):\n",
    "            def_verts.append(rtf_model.inverse(sample.to(DEVICE)).cpu().numpy())\n",
    "    def_verts = np.concatenate(def_verts, axis=0)\n",
    "    mesh_deform = trimesh.Trimesh(def_verts, mesh_input.faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOVING_HANDLES = [\"assets/constraints/dino/transforms/snout_point_down.txt\"]\n",
    "STATIC_HANDLES = [\"assets/constraints/dino/parts/left_foot.txt\",\n",
    "                  \"assets/constraints/dino/parts/right_foot.txt\"]\n",
    "\n",
    "moving_pts = np.concatenate([np.loadtxt(f) for f in MOVING_HANDLES], axis=0)\n",
    "if len(moving_pts.shape) < 2:\n",
    "    moving_pts = moving_pts.reshape(1, 3)\n",
    "static_pts = np.concatenate([np.loadtxt(f) for f in STATIC_HANDLES], axis=0)\n",
    "\n",
    "ps.register_surface_mesh(\"Deformed Mesh\", mesh_deform.vertices, mesh_deform.faces)\n",
    "ps.register_point_cloud(\"Moving Points\", moving_pts)\n",
    "ps.register_point_cloud(\"Static Points\", static_pts)\n",
    "ps.show()\n",
    "ps.remove_all_structures()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_global_metrics = {\n",
    "    'area': mesh_input.area,\n",
    "    'volume': mesh_input.volume\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "deform_global_metrics = {\n",
    "    'area': mesh_deform.area,\n",
    "    'volume': mesh_deform.volume\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "area preservation: 101.69%\n",
      "volume preservation: 103.75%\n"
     ]
    }
   ],
   "source": [
    "for k in source_global_metrics.keys():\n",
    "    perc = (source_global_metrics[k] / deform_global_metrics[k]) * 100.\n",
    "    print(f\"{k} preservation: {perc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topology properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = mesh_input.edges\n",
    "source_local_metrics = {\n",
    "    'edge_lengths': np.linalg.norm(\n",
    "        mesh_input.vertices[edges[:, 0]] - mesh_input.vertices[edges[:, 1]], axis=-1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "deform_local_metrics = {\n",
    "    'edge_lengths': np.linalg.norm(\n",
    "        mesh_deform.vertices[edges[:, 0]] - mesh_deform.vertices[edges[:, 1]], axis=-1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_lengths preservation: 7.596860775419095e-06%\n"
     ]
    }
   ],
   "source": [
    "for k in source_local_metrics.keys():\n",
    "    error = source_local_metrics[k] - deform_local_metrics[k]\n",
    "    print(f\"{k} preservation: {error.mean()}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Fields Deformation\n",
    "\n",
    "Properties are evaluated on the marching cubes mesh obtained from the inverted deformation field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_source = trimesh.Trimesh(shape_verts, shape_faces)\n",
    "mesh_source.fix_normals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_eval = []\n",
    "with torch.no_grad():\n",
    "    for sample in tqdm(torch.split(volume, CHUNK, dim=0)):\n",
    "        f_eval.append(sdf_model(rtf_model.inverse(sample.contiguous()))['dist'].cpu().numpy())\n",
    "f_volume = np.concatenate(f_eval, axis=0).reshape(*([MC_RESOLUTION] * 3))\n",
    "def_verts, def_faces = mcubes.marching_cubes(f_volume, 0.0)\n",
    "def_verts /= MC_RESOLUTION // 2\n",
    "def_verts -= 1.0\n",
    "\n",
    "mesh_deform = trimesh.Trimesh(def_verts, def_faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_global_metrics = {\n",
    "    'area': mesh_source.area,\n",
    "    'volume': mesh_source.volume\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "deform_global_metrics = {\n",
    "    'area': mesh_deform.area,\n",
    "    'volume': mesh_deform.volume\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "area preservation: 101.15%\n",
      "volume preservation: -100.31%\n"
     ]
    }
   ],
   "source": [
    "for k in source_global_metrics.keys():\n",
    "    perc = (source_global_metrics[k] / deform_global_metrics[k]) * 100.\n",
    "    print(f\"{k} preservation: {perc:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdfedit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
